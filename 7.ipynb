{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af14a7ba",
   "metadata": {},
   "source": [
    "1. What is the definition of a target function? In the sense of a real-life example, express the target function. How is a target function's fitness assessed?\n",
    ":A target function, in machine learning, is a method for solving a problem that an AI algorithm parses its training data to find. Once an algorithm finds its target function, that function can be used to predict results.\n",
    "\n",
    "2. What are predictive models, and how do they work? What are descriptive types, and how do you use them? Examples of both types of models should be provided. Distinguish between these two forms of models.\n",
    ":A descriptive model will exploit the past data that are stored in databases and provide you with the accurate report. In a Predictive model, it identifies patterns found in past and transactional data to find risks and future outcomes.\n",
    "> Predictive modeling solutions are a form of data-mining technology that works by analyzing historical and current data and generating a model to help predict future outcomes.Predictive models analyze past performance to assess how likely a customer is to exhibit a specific behavior in the future.\n",
    ">  descriptive model describes a system or other entity and its relationship to its environment. It is generally used to help specify and/or understand what the system is, what it does, and how it does it.\n",
    "\n",
    "3. Describe the method of assessing a classification model's efficiency in detail. Describe the various measurement parameters.\n",
    ":Logarithmic loss (or log loss) measures the performance of a classification model where the prediction is a probability value between 0 and 1. Log loss increases as the predicted probability diverge from the actual label.The key classification metrics: Accuracy, Recall, Precision,Confusion matrix and F1- Score.\n",
    "\n",
    "4. \n",
    "i. In the sense of machine learning models, what is underfitting? What is the most common reason for underfitting?\n",
    ":Underfitting is a scenario in data science where a data model is unable to capture the relationship between the input and output variables accurately, generating a \"HIGH ERROR\" rate on both the training set and unseen data.\n",
    "Underfitting occurs when a model is too simple — informed by too few features or regularized too much — which makes it inflexible in learning from the dataset. Simple learners tend to have less variance in their predictions but more bias towards wrong outcomes.\n",
    "\n",
    "ii. What does it mean to overfit? When is it going to happen?\n",
    ": for Train data Accuracy is high but for test data accuracy goes down.Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model.\n",
    "\n",
    "iii. In the sense of model fitting, explain the bias-variance trade-off.\n",
    ":What is bias vs variance tradeoff?\n",
    "Bias is the simplifying assumptions made by the model to make the target function easier to approximate. Variance is the amount that the estimate of the target function will change given different training data. Trade-off is tension between the error introduced by the bias and the variance.\n",
    "\n",
    "5. Is it possible to boost the efficiency of a learning model? If so, please clarify how.\n",
    ": Yes it is possible to boost the efficiency of a learning model.\n",
    "by,\n",
    "Adding more data,Treat missing and Outlier values,Feature Engineering,Feature Selection,Multiple algorithms,Algorithm Tuning,Ensemble methods.\n",
    "\n",
    "6. How would you rate an unsupervised learning model's success? What are the most common success indicators for an unsupervised learning model?\n",
    ":unsupervised learning model's success can be evaluated through Silhouette Score,Adjusted Rand Index.Clustering Performance Evaluation Metrics Clustering is the most common form of unsupervised learning.\n",
    "\n",
    "7.Is it possible to use a classification model for numerical data or a regression model for categorical data with a classification model? Explain your answer.\n",
    ":\n",
    "\n",
    "8. Describe the predictive modeling method for numerical values. What distinguishes it from categorical predictive modeling?\n",
    ": predictive modeling is a statistical technique using machine learning and data mining to predict and forecast likely future outcomes with the aid of historical and existing data. It works by analyzing current and historical data and projecting what it learns on a model generated to forecast likely outcomes.Classification methods are used to predict cateorical data.\n",
    "\n",
    "9. The following data were collected when using a classification model to predict the malignancy of a group of patients' tumors:\n",
    "i. Accurate estimates – 15 cancerous, 75 benign\n",
    "ii. Wrong predictions – 3 cancerous, 7 benign\n",
    "Determine the model's error rate, Kappa value, sensitivity, precision, and F-measure.\n",
    "\n",
    "10. Make quick notes on:\n",
    "1. The process of holding out\n",
    ":Hold-out is when you split up your dataset into a 'train' and 'test' set. The training set is what the model is trained on, and the test set is used to see how well that model performs on unseen data.\n",
    "\n",
    "2. Cross-validation by tenfold\n",
    ": Cross-validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train the model, and a test set to evaluate it.In k-fold cross-validation, the original sample is randomly partitioned into k equal size subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k-1 subsamples are used as training data. \n",
    "\n",
    "3. Adjusting the parameters\n",
    ":Model training typically starts with parameters being initialized to some values (random values or set to zeros). As training/learning progresses the initial values are updated using an optimization algorithm (e.g. gradient descent). The learning algorithm is continuously updating the parameter values as learning progress but hyperparameter values set by the model designer remain unchanged.At the end of the learning process, model parameters are what constitute the model itself.\n",
    "\n",
    "11. Define the following terms: \n",
    "1. Purity vs. Silhouette width\n",
    ":the silhouette width is also an estimate of the average distance between clusters. Its value is comprised between 1 and -1 with a value of 1 indicating a very good cluster.Purity is a measure of the extent to which clusters contain a single class. Its calculation can be thought of as follows: For each cluster, count the number of data points from the most common class in said cluster.\n",
    "\n",
    "2. Boosting vs. Bagging\n",
    ":Bagging is usually applied where the classifier is unstable and has a high variance. Boosting is usually applied where the classifier is stable and simple and has high bias.\n",
    "\n",
    "3. The eager learner vs. the lazy learner\n",
    ":A lazy learner delays abstracting from the data until it is asked to make a prediction while an eager learner abstracts away from the data during training and uses this abstraction to make predictions rather than directly compare queries with instances in the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
