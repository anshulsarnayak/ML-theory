{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba3b12ab",
   "metadata": {},
   "source": [
    "1. What is prior probability? Give an example.\n",
    ":Prior probability shows the likelihood of an outcome in a given dataset. For example, in the mortgage case, P(Y) is the default rate on a home mortgage, which is 2%. P(Y|X) is called the conditional probability, which provides the probability of an outcome given the evidence, that is, when the value of X is known.\n",
    "\n",
    "2. What is posterior probability? Give an example.\n",
    ": the posterior probability of a random event or an uncertain proposition is the conditional probability given the relevant evidence or background.\n",
    "\n",
    "3. What is likelihood probability? Give an example.\n",
    ": Likelihood is about an infinite set of possible probabilities, given an outcome.\n",
    "\n",
    "4. What is Naïve Bayes classifier? Why is it named so?\n",
    ": naive Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong independence assumptions between the features.Naive Bayes is called naive because it assumes that each input variable is independent.\n",
    "\n",
    "5. What is optimal Bayes classifier?\n",
    ": Bayes Optimal Classifier is a probabilistic model that makes the most probable prediction.\n",
    "\n",
    "6. Write any two features of Bayesian learning methods.\n",
    ":Features of Bayesian learning methods:\n",
    "– a probability distribution over observed data for each possible hypothesis. New instances can be classified by combining the predictions of multiple hypotheses, weighted by their probabilities.\n",
    "\n",
    "7. Define the concept of consistent learners.\n",
    ": • A learner L using a hypothesis H and training data D is said to be a consistent learner if it always outputs a hypothesis with zero error on D whenever H contains such a hypothesis. • By definition, a consistent learner must produce a hypothesis in the version space for H given D.\n",
    "\n",
    "8. Write any two strengths of Bayes classifier.\n",
    ":It is simple and easy to implement.\n",
    "It doesn't require as much training data.\n",
    "It handles both continuous and discrete data.\n",
    "\n",
    "9. Write any two weaknesses of Bayes classifier.\n",
    ":Naive Bayes assumes that all predictors (or features) are independent, rarely happening in real life.\n",
    "This algorithm faces the 'zero-frequency problem' where it assigns zero probability to a categorical variable whose category in the test data set wasn't available in the training dataset.\n",
    "\n",
    "10. Explain how Naïve Bayes classifier is used for\n",
    "\n",
    "        1. Text classification\n",
    "            :Naive Bayesian algorithm is a simple classification algorithm which uses probability of the events for its purpose. It is based on the Bayes Theorem which assumes that there is no interdependence amongst the variables.\n",
    "            \n",
    "        2. Spam filtering\n",
    "            :With Bayes' Rule, we want to find the probability an email is spam, given it contains certain words. We do this by finding the probability that each word in the email is spam, and then multiply these probabilities together to get the overall email spam metric to be used in classification.\n",
    "            \n",
    "       3. Market sentiment analysis\n",
    "            :Naive Bayes is the simplest and fastest classification algorithm for a large chunk of data that is why it is used for market sentimental analysis.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
