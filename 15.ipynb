{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24dfb84d",
   "metadata": {},
   "source": [
    "1. Recognize the differences between supervised, semi-supervised, and unsupervised learning.\n",
    ":The main difference between supervised and unsupervised learning: Labeled data. The main distinction between the two approaches is the use of labeled datasets. To put it simply, supervised learning uses labeled input and output data, while an unsupervised learning algorithm does not.Semi-supervised learning aims to label unlabeled data points using knowledge learned from a small number of labeled data points\n",
    "    \n",
    "2. Describe in detail any five examples of classification problems.\n",
    ":Customer behavior prediction: Customers can be classified into different categories based on their buying patterns, web store browsing patterns etc. For example, classification models can be used to determine whether a customer is likely to purchase more items or not. If the classification model predicts a greater likelihood that they are about to make more purchases, then you might want to send them promotional offers and discounts accordingly. Or if it has been determined that they will probably fall off of their purchasing habits soon, maybe save them for later by making their information readily available.\n",
    "\n",
    "Document classification: A multinomial classification model can be trained to classify documents in different categories.\n",
    "\n",
    "Image classification: A multinomial classification model can be trained to classify images into different categories. For example, in order to classify images of dogs and cats for use within machine vision systems, machine learning techniques can help automate this process based on pre-classified images of dogs and cats.rent categories\n",
    "\n",
    "Web text classification: Classifies web text or assign tag to web text based on pre-determined categories learned from the past data. For example, classification models can be used to automatically classify web text into one of the following categories: Sports, Entertainment, or Technology.\n",
    "\n",
    "Ad click-through rate prediction: Binary classification models can be used to predict whether one or more ads on the website will be clicked or not. Such models are used to optimize the ad inventory on websites by selecting which ads will have a better chance of being clicked. A machine learning classification model can be built using historical data about what types of users do or don’t click on certain ads, along with information like demographics and content within each web page where an ad appears; then it is used to predict the chances that a user will click on an ad.\n",
    "\n",
    "3. Describe each phase of the classification process in detail.\n",
    ":Step 1: Split the data.\n",
    "Step 2: Choose dependent variable.\n",
    "Step 3: Simple Analysis.\n",
    "Step 4: Classification and Interpretation.\n",
    "Step 5: Validation accuracy.\n",
    "    \n",
    "4. Go through the SVM model in depth using various scenarios.\n",
    ":\n",
    "Identify the right hyper-plane (Scenario-1): Here, we have three hyper-planes (A, B, and C). Now, identify the right hyper-plane to classify stars and circles. thumb rule to identify the right hyper-plane: “Select the hyper-plane which segregates the two classes better”. In this scenario, hyper-plane “B” has excellently performed this job\n",
    " \n",
    "Identify the right hyper-plane (Scenario-2): Here, we have three hyper-planes (A, B, and C) and all are segregating the classes well.maximizing the distances between nearest data point (either class) and hyper-plane will help us to decide the right hyper-plane. This distance is called as Margin.\n",
    "\n",
    "5. What are some of the benefits and drawbacks of SVM?\n",
    ":benefits: SVM works relatively well when there is a clear margin of separation between classes. SVM is more effective in high dimensional spaces. SVM is effective in cases where the number of dimensions is greater than the number of samples. SVM is relatively memory efficient.\n",
    "\n",
    "drawbacks: SVM algorithm is not suitable for large data sets.\n",
    "SVM does not perform very well when the data set has more noise i.e. target classes are overlapping.\n",
    "In cases where the number of features for each data point exceeds the number of training data samples, the SVM will underperform.\n",
    "    \n",
    "6. Go over the kNN model in depth.\n",
    ":kNN is the simplest machine learning algorithm to understand and also to explain. It is a versatile algorithm i.e. useful for both classification and regression. It has one big advantage is that kNN ha no pre assumption about the data. “ Let the data speak for itself ”.\n",
    "    \n",
    "7. Discuss the kNN algorithm's error rate and validation error.\n",
    ": The error rate at K=1 is always zero for the training sample. This is because the closest point to any training data point is itself.Cross-validation is when the dataset is randomly split up into 'k' groups. One of the groups is used as the test set and the rest are used as the training set. The model is trained on the training set and scored on the test set. Then the process is repeated until each unique group as been used as the test set.\n",
    "    \n",
    "8. For KNN ,  talk about how to measure the difference between the test and training results.\n",
    ":\n",
    "    \n",
    "9. Create the kNN algorithm.\n",
    ":\n",
    "The k-nearest neighbor algorithm is imported from the scikit-learn package.\n",
    "Create feature and target variables.\n",
    "Split data into training and test data.\n",
    "Generate a k-NN model using neighbors value.\n",
    "Train or fit the data into the model.\n",
    "Predict the future.\n",
    "    \n",
    "10. What is a decision tree, exactly? What are the various kinds of nodes? Explain all in depth.\n",
    ":A decision tree is a decision support tool that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.\n",
    "\n",
    "There are three different types of nodes: chance nodes, decision nodes, and end nodes. A chance node, represented by a circle, shows the probabilities of certain results. A decision node, represented by a square, shows a decision to be made, and an end node shows the final outcome of a decision path.\n",
    "    \n",
    "11. Describe the different ways to scan a decision tree.\n",
    ":\n",
    "    \n",
    "12. Describe in depth the decision tree algorithm.\n",
    ":Tree depth is a measure of how many splits a tree can make before coming to a prediction. This process could be continued further with more splitting until the tree is as pure as possible. The problem with many repetitions of this process is that this can lead to a very deep classification tree with many nodes\n",
    "\n",
    "13. In a decision tree, what is inductive bias? What would you do to stop overfitting?\n",
    ":The inductive bias (also known as learning bias) of a learning algorithm is the set of assumptions that the learner uses to predict outputs of given inputs that it has not encountered.\n",
    "\n",
    "Pruning refers to a technique to remove the parts of the decision tree to prevent growing to its full depth. By tuning the hyperparameters of the decision tree model one can prune the trees and prevent them from overfitting. There are two types of pruning Pre-pruning and Post-pruning.\n",
    "\n",
    "14. Explain advantages and disadvantages of using a decision tree?\n",
    ":Advantages and Disadvantages of Decision Trees in Machine Learning. Decision Tree is used to solve both classification and regression problems. But the main drawback of Decision Tree is that it generally leads to overfitting of the data.\n",
    "\n",
    "15. Describe in depth the problems that are suitable for decision tree learning.\n",
    ":Appropriate Problems for Decision Tree Learning:\n",
    "Instances are represented by attribute-value pairs.\n",
    "The target function has discrete output values.\n",
    "Disjunctive descriptions may be required. \n",
    "The training data may contain errors. \n",
    "The training data may contain missing attribute values.\n",
    "\n",
    "16. Describe in depth the random forest model. What distinguishes a random forest?\n",
    ":A decision tree combines some decisions, whereas a random forest combines several decision trees. Thus, it is a long process, yet slow. Whereas, a decision tree is fast and operates easily on large data sets, especially the linear one. The random forest model needs rigorous training.\n",
    "\n",
    "17. In a random forest, talk about OOB error and variable value.\n",
    ":The out-of-bag (OOB) error is the average error for each calculated using predictions from the trees that do not contain in their respective bootstrap sample.\n",
    "For each variable, the sum of the Gini decrease across every tree of the forest is accumulated every time that variable is chosen to split a node. The sum is divided by the number of trees in the forest to give an average. The scale is irrelevant: only the relative values matter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
